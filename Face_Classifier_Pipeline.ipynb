{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_images'    # folder containing training images\n",
    "test_dir = './test_images'    # folder containing test images\n",
    "\n",
    "valid_size = 0.2   # proportion of validation set (80% train, 20% validation)\n",
    "batch_size = 32  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(train_dataset, test_dataset, validation_size=0.2, batch_size=32, unbalanced=False):\n",
    "    # Define randomly the indices of examples to use for training and for validation\n",
    "    num_train = len(train_dataset)\n",
    "    indices_train = list(range(num_train))\n",
    "    np.random.shuffle(indices_train)\n",
    "    split_tv = int(np.floor(validation_size * num_train))\n",
    "    \n",
    "    train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "    if not unbalanced:\n",
    "        # Define two \"samplers\" that will randomly pick examples from the training and validation set\n",
    "        train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    else:\n",
    "        # Define two \"samplers\" that will randomly pick examples from the training and validation set in an unbalanced way\n",
    "        train_sampler = ImbalancedDatasetSampler(train_dataset, train_new_idx)\n",
    "        valid_sampler = ImbalancedDatasetSampler(train_dataset, valid_idx)\n",
    "        \n",
    "    # Dataloaders (take care of loading the data from disk, batch by batch, during training)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),   # transforms to gray-scale (1 input channel)\n",
    "     transforms.ToTensor(),    # transforms to Torch tensor (needed for PyTorch)\n",
    "     transforms.Normalize(mean=(0.5,),std=(0.5,))]) # subtracts mean (0.5) and devides by standard deviation (0.5) -> resulting values in (-1, +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two pytorch datasets (train/test) \n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Define the train_data loader, validation_data loader, test_data loader\n",
    "train_loader, valid_loader, test_loader = create_dataloader(train_data, test_data, 0.2, 32, unbalanced=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will determine the optimizer for our neural network, i.e the algorithm to adjust model's parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "n_epochs = 32\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 214.3142853\n",
      "epoch: 2, running_loss: 62.5703545\n",
      "epoch: 3, running_loss: 38.7535667\n",
      "epoch: 4, running_loss: 29.8845310\n",
      "epoch: 5, running_loss: 23.4209633\n",
      "epoch: 6, running_loss: 19.9186306\n",
      "epoch: 7, running_loss: 17.7311115\n",
      "epoch: 8, running_loss: 14.0981884\n",
      "epoch: 9, running_loss: 14.9567232\n",
      "epoch: 10, running_loss: 13.0569525\n",
      "epoch: 11, running_loss: 9.7059460\n",
      "epoch: 12, running_loss: 10.8036327\n",
      "epoch: 13, running_loss: 10.3880339\n",
      "epoch: 14, running_loss: 9.7510948\n",
      "epoch: 15, running_loss: 9.2061424\n",
      "epoch: 16, running_loss: 9.8168344\n",
      "epoch: 17, running_loss: 8.4004841\n",
      "epoch: 18, running_loss: 8.3007460\n",
      "epoch: 19, running_loss: 7.4232326\n",
      "epoch: 20, running_loss: 8.7580853\n",
      "epoch: 21, running_loss: 8.1304035\n",
      "epoch: 22, running_loss: 7.0545006\n",
      "epoch: 23, running_loss: 7.9373608\n",
      "epoch: 24, running_loss: 6.8218036\n",
      "epoch: 25, running_loss: 7.5354710\n",
      "epoch: 26, running_loss: 5.8522930\n",
      "epoch: 27, running_loss: 7.3025656\n",
      "epoch: 28, running_loss: 6.3039107\n",
      "epoch: 29, running_loss: 6.6608810\n",
      "epoch: 30, running_loss: 7.6602869\n",
      "epoch: 31, running_loss: 6.2263494\n",
      "epoch: 32, running_loss: 7.3110337\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader: \n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.611956 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.6f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for augmentation\n",
    "transforms_train_augmented = transforms.Compose([\n",
    "    transforms.Grayscale(), \n",
    "    transforms.RandomResizedCrop(36),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,),std=(0.5,))\n",
    "])       \n",
    "\n",
    "net_augmented = Net()\n",
    "\n",
    "optimizer = optim.Adam(net_augmented.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pytorch augmented train datasets \n",
    "train_data_augmented = torchvision.datasets.ImageFolder(train_dir, transform=transforms_train_augmented)\n",
    "\n",
    "# Define the train_data loader, validation_data loader, test_data loader\n",
    "train_loader, valid_loader, test_loader = create_dataloader(train_data_augmented, test_data, 0.2, 32, unbalanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 769.6201172\n",
      "epoch: 2, running_loss: 454.5734558\n",
      "epoch: 3, running_loss: 362.4648743\n",
      "epoch: 4, running_loss: 323.7208252\n",
      "epoch: 5, running_loss: 290.5789185\n",
      "epoch: 6, running_loss: 279.4784851\n",
      "epoch: 7, running_loss: 266.4322815\n",
      "epoch: 8, running_loss: 248.9024353\n",
      "epoch: 9, running_loss: 243.9502106\n",
      "epoch: 10, running_loss: 239.5317688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 32\n",
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader: \n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net_augmented(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10.448348 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net_augmented(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.6f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two pytorch datasets (train/test) \n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Define the train_data loader, validation_data loader, test_data loader\n",
    "train_loader, valid_loader, test_loader = create_dataloader(train_data, test_data, 0.2, 32, unbalanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 10.3706675\n",
      "epoch: 2, running_loss: 7.0060797\n",
      "epoch: 3, running_loss: 7.4594674\n",
      "epoch: 4, running_loss: 6.1392665\n",
      "epoch: 5, running_loss: 7.0472698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\5IF\\OT2_ML\\deep_learning_project\\Face_Classifier_Pipeline.ipynb Cell 17\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):  \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#   loop over iterations: one iteration = 1 batch of examples\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m train_loader: \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# zero the gradient buffers\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/5IF/OT2_ML/deep_learning_project/Face_Classifier_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         output \u001b[39m=\u001b[39m net(data)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader: \n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_map = {\"TP\" : 0,\n",
    "                      \"FP\" : 0,\n",
    "                      \"TN\" : 0,\n",
    "                      \"FN\" : 0}\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        for i in range(0,len(labels)):\n",
    "            if predicted[i].item() == labels[i].item():\n",
    "                if predicted[i].item() == 1:\n",
    "                    classification_map[\"TP\"] +=1\n",
    "                else:\n",
    "                    classification_map[\"TN\"] +=1\n",
    "            elif predicted[i].item() == 1:\n",
    "                classification_map[\"FP\"] +=1\n",
    "            else: \n",
    "                classification_map[\"FN\"] +=1\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.6f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_map = {\n",
    "            \"Specificity\" : float(classification_map[\"TN\"]) / float(classification_map[\"TN\"] + classification_map[\"FP\"]),\n",
    "            \"Recall\" : float(classification_map[\"TP\"]) / float(classification_map[\"TP\"] + classification_map[\"FN\"]),\n",
    "            \"Precision\" : float(classification_map[\"TP\"]) / float(classification_map[\"TP\"] + classification_map[\"FP\"]),\n",
    "            \"Accuracy\" : float(classification_map[\"TP\"] + classification_map[\"TN\"]) / float(classification_map[\"TP\"] + classification_map[\"TN\"] + classification_map[\"FP\"] + classification_map[\"FN\"])\n",
    "        }\n",
    "stats_map[\"F-score\"] = 2.0 / float((1.0 / float(stats_map[\"Precision\"])) + (1.0 / float(stats_map[\"Recall\"])))\n",
    "\n",
    "for key, value in stats_map.items():\n",
    "    print(key, \": \", value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
