{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from net import Net\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Use CUDA if possible\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_images'    # folder containing training images\n",
    "test_dir = './test_images'    # folder containing test images\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),   # transforms to gray-scale (1 input channel)\n",
    "     transforms.ToTensor(),    # transforms to Torch tensor (needed for PyTorch)\n",
    "     transforms.Normalize(mean=(0.5,),std=(0.5,))]) # subtracts mean (0.5) and devides by standard deviation (0.5) -> resulting values in (-1, +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two pytorch datasets (train/test) \n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2   # proportion of validation set (80% train, 20% validation)\n",
    "batch_size = 32    \n",
    "\n",
    "# Define randomly the indices of examples to use for training and for validation\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two \"samplers\" that will randomly pick examples from the unbalanced training and validation set\n",
    "train_sampler = ImbalancedDatasetSampler(train_data, train_new_idx)\n",
    "valid_sampler = ImbalancedDatasetSampler(train_data, valid_idx)\n",
    "\n",
    "# Dataloaders (take care of loading the data from disk, batch by batch, during training)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "classes = ('noface','face')  # indicates that \"1\" means \"face\" and \"0\" non-face (only used for display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  73376\n",
      "test:  7628\n",
      "26950\n"
     ]
    }
   ],
   "source": [
    "print (\"train: \", len(train_sampler))\n",
    "print (\"test: \", len(test_data))\n",
    "count =0\n",
    "\n",
    "for i in range(0,len(train_sampler)):\n",
    "    if train_sampler._get_label(train_data,i) == 0:\n",
    "        count +=1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "n_epochs = 32\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_map = {\"TP\" : 0,\n",
    "                      \"FP\" : 0,\n",
    "                      \"TN\" : 0,\n",
    "                      \"FN\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 168.4761353\n",
      "epoch: 2, running_loss: 45.3047829\n",
      "epoch: 3, running_loss: 32.8437576\n",
      "epoch: 4, running_loss: 25.0212345\n",
      "epoch: 5, running_loss: 21.7288227\n",
      "epoch: 6, running_loss: 18.1002312\n",
      "epoch: 7, running_loss: 15.6587963\n",
      "epoch: 8, running_loss: 13.9877157\n",
      "epoch: 9, running_loss: 13.2276754\n",
      "epoch: 10, running_loss: 12.8625126\n",
      "epoch: 11, running_loss: 11.3820152\n",
      "epoch: 12, running_loss: 13.2031689\n",
      "epoch: 13, running_loss: 10.7207289\n",
      "epoch: 14, running_loss: 10.9330978\n",
      "epoch: 15, running_loss: 9.3848009\n",
      "epoch: 16, running_loss: 9.4787989\n",
      "epoch: 17, running_loss: 8.9973955\n",
      "epoch: 18, running_loss: 10.2980118\n",
      "epoch: 19, running_loss: 7.9035530\n",
      "epoch: 20, running_loss: 7.2286773\n",
      "epoch: 21, running_loss: 8.0139933\n",
      "epoch: 22, running_loss: 7.0642419\n",
      "epoch: 23, running_loss: 4.7437434\n",
      "epoch: 24, running_loss: 8.2998848\n",
      "epoch: 25, running_loss: 7.0300188\n",
      "epoch: 26, running_loss: 7.4751620\n",
      "epoch: 27, running_loss: 7.9221659\n",
      "epoch: 28, running_loss: 7.5973816\n",
      "epoch: 29, running_loss: 6.4597087\n",
      "epoch: 30, running_loss: 4.9349608\n",
      "epoch: 31, running_loss: 7.7433214\n",
      "epoch: 32, running_loss: 6.1811676\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.228107 %\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "classification_map = {\"TP\" : 0,\n",
    "                      \"FP\" : 0,\n",
    "                      \"TN\" : 0,\n",
    "                      \"FN\" : 0}\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        count+=1\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        for i in range(0,len(labels)):\n",
    "            if predicted[i].item() == labels[i].item():\n",
    "                if predicted[i].item() == 1:\n",
    "                    classification_map[\"TP\"] +=1\n",
    "                else:\n",
    "                    classification_map[\"TN\"] +=1\n",
    "            elif predicted[i].item() == 1:\n",
    "                classification_map[\"FP\"] +=1\n",
    "            else: \n",
    "                classification_map[\"FN\"] +=1\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.6f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n",
      "6786\n",
      "45\n",
      "319\n",
      "Specificity :  0.9934123847167325\n",
      "Recall :  0.5997490589711418\n",
      "Precision :  0.9139579349904398\n",
      "Accuracy :  0.9522810697430519\n",
      "F-score :  0.7242424242424242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (classification_map[\"TP\"])\n",
    "print (classification_map[\"TN\"])\n",
    "print (classification_map[\"FP\"])\n",
    "print (classification_map[\"FN\"])\n",
    "\n",
    "stats_map = {\n",
    "            \"Specificity\" : float(classification_map[\"TN\"]) / float(classification_map[\"TN\"] + classification_map[\"FP\"]),\n",
    "            \"Recall\" : float(classification_map[\"TP\"]) / float(classification_map[\"TP\"] + classification_map[\"FN\"]),\n",
    "            \"Precision\" : float(classification_map[\"TP\"]) / float(classification_map[\"TP\"] + classification_map[\"FP\"]),\n",
    "            \"Accuracy\" : float(classification_map[\"TP\"] + classification_map[\"TN\"]) / float(classification_map[\"TP\"] + classification_map[\"TN\"] + classification_map[\"FP\"] + classification_map[\"FN\"])\n",
    "        }\n",
    "stats_map[\"F-score\"] = 2.0 / float((1.0 / float(stats_map[\"Precision\"])) + (1.0 / float(stats_map[\"Recall\"])))\n",
    "\n",
    "for key, value in stats_map.items():\n",
    "    print(key, \": \", value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
