{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Use CUDA if possible\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_images'    # folder containing training images\n",
    "test_dir = './test_images'    # folder containing test images\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),   # transforms to gray-scale (1 input channel)\n",
    "     transforms.ToTensor(),    # transforms to Torch tensor (needed for PyTorch)\n",
    "     transforms.Normalize(mean=(0.5,),std=(0.5,))]) # subtracts mean (0.5) and devides by standard deviation (0.5) -> resulting values in (-1, +1)\n",
    "\n",
    "# Define the transformations for augmentation\n",
    "transforms_augmented = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(), \n",
    "        transforms.RandomResizedCrop(36),\n",
    "        transforms.RandomHorizontalFlip(0.25),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,),std=(0.5,))\n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        transforms.Grayscale(), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=(0.5,),std=(0.5,))])        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two pytorch datasets (train/test) \n",
    "train_data_augmented = torchvision.datasets.ImageFolder(train_dir, transform=transforms_augmented['train'])\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2   # proportion of validation set (80% train, 20% validation)\n",
    "batch_size = 128\n",
    "\n",
    "# Define randomly the indices of examples to use for training and for validation\n",
    "num_train = len(train_data_augmented)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "# Define two \"samplers\" that will randomly pick examples from the training and validation set\n",
    "train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders (take care of loading the data from disk, batch by batch, during training)\n",
    "train_loader = torch.utils.data.DataLoader(train_data_augmented, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data_augmented, batch_size=batch_size, sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "classes = ('noface','face')  # indicates that \"1\" means \"face\" and \"0\" non-face (only used for display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "n_epochs = 64\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 233.0632935\n",
      "epoch: 2, running_loss: 158.7202454\n",
      "epoch: 3, running_loss: 126.3238373\n",
      "epoch: 4, running_loss: 104.8042374\n",
      "epoch: 5, running_loss: 92.1080246\n",
      "epoch: 6, running_loss: 81.6177216\n",
      "epoch: 7, running_loss: 77.5640030\n",
      "epoch: 8, running_loss: 72.5069427\n",
      "epoch: 9, running_loss: 67.0175323\n",
      "epoch: 10, running_loss: 65.3389130\n",
      "epoch: 11, running_loss: 62.1663666\n",
      "epoch: 12, running_loss: 59.0074997\n",
      "epoch: 13, running_loss: 57.4701843\n",
      "epoch: 14, running_loss: 52.4946747\n",
      "epoch: 15, running_loss: 55.2193222\n",
      "epoch: 16, running_loss: 54.0557480\n",
      "epoch: 17, running_loss: 52.0162621\n",
      "epoch: 18, running_loss: 49.1355820\n",
      "epoch: 19, running_loss: 50.1782341\n",
      "epoch: 20, running_loss: 47.5283928\n",
      "epoch: 21, running_loss: 47.3824615\n",
      "epoch: 22, running_loss: 45.9070282\n",
      "epoch: 23, running_loss: 45.7562408\n",
      "epoch: 24, running_loss: 43.8760719\n",
      "epoch: 25, running_loss: 43.5629616\n",
      "epoch: 26, running_loss: 43.0898781\n",
      "epoch: 27, running_loss: 43.7409859\n",
      "epoch: 28, running_loss: 42.3698311\n",
      "epoch: 29, running_loss: 42.9740982\n",
      "epoch: 30, running_loss: 42.5553474\n",
      "epoch: 31, running_loss: 41.4230461\n",
      "epoch: 32, running_loss: 40.6091003\n",
      "epoch: 33, running_loss: 40.3727417\n",
      "epoch: 34, running_loss: 40.6560898\n",
      "epoch: 35, running_loss: 39.6766663\n",
      "epoch: 36, running_loss: 40.4515190\n",
      "epoch: 37, running_loss: 39.8491859\n",
      "epoch: 38, running_loss: 38.9088135\n",
      "epoch: 39, running_loss: 39.8823433\n",
      "epoch: 40, running_loss: 39.2554131\n",
      "epoch: 41, running_loss: 38.7231636\n",
      "epoch: 42, running_loss: 38.1909256\n",
      "epoch: 43, running_loss: 37.6272278\n",
      "epoch: 44, running_loss: 37.9774628\n",
      "epoch: 45, running_loss: 37.5722160\n",
      "epoch: 46, running_loss: 38.3399010\n",
      "epoch: 47, running_loss: 36.8600273\n",
      "epoch: 48, running_loss: 36.9503365\n",
      "epoch: 49, running_loss: 36.8302917\n",
      "epoch: 50, running_loss: 35.3801193\n",
      "epoch: 51, running_loss: 36.6434975\n",
      "epoch: 52, running_loss: 36.8974075\n",
      "epoch: 53, running_loss: 37.0592918\n",
      "epoch: 54, running_loss: 36.6035995\n",
      "epoch: 55, running_loss: 35.9650726\n",
      "epoch: 56, running_loss: 35.0061607\n",
      "epoch: 57, running_loss: 36.1662560\n",
      "epoch: 58, running_loss: 35.6052055\n",
      "epoch: 59, running_loss: 35.0995560\n",
      "epoch: 60, running_loss: 36.5660820\n",
      "epoch: 61, running_loss: 35.5198364\n",
      "epoch: 62, running_loss: 34.9318581\n",
      "epoch: 63, running_loss: 34.9077835\n",
      "epoch: 64, running_loss: 35.8564835\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.954903 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.6f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
