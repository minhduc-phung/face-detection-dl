{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Use CUDA if possible\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_images'    # folder containing training images\n",
    "test_dir = './test_images'    # folder containing test images\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),   # transforms to gray-scale (1 input channel)\n",
    "     transforms.ToTensor(),    # transforms to Torch tensor (needed for PyTorch)\n",
    "     transforms.Normalize(mean=(0.5,),std=(0.5,))]) # subtracts mean (0.5) and devides by standard deviation (0.5) -> resulting values in (-1, +1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two pytorch datasets (train/test) \n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2   # proportion of validation set (80% train, 20% validation)\n",
    "batch_size = 64\n",
    "\n",
    "# Define randomly the indices of examples to use for training and for validation\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "# Define two \"samplers\" that will randomly pick examples from the training and validation set\n",
    "train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "91720"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders (take care of loading the data from disk, batch by batch, during training)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "classes = ('noface','face')  # indicates that \"1\" means \"face\" and \"0\" non-face (only used for display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "n_epochs = 32\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, running_loss: 114.6123581\n",
      "epoch: 2, running_loss: 32.4427681\n",
      "epoch: 3, running_loss: 20.8305912\n",
      "epoch: 4, running_loss: 15.7457180\n",
      "epoch: 5, running_loss: 13.8158321\n",
      "epoch: 6, running_loss: 10.3512211\n",
      "epoch: 7, running_loss: 8.9673786\n",
      "epoch: 8, running_loss: 8.8329029\n",
      "epoch: 9, running_loss: 5.9363403\n",
      "epoch: 10, running_loss: 7.0416312\n",
      "epoch: 11, running_loss: 5.3102298\n",
      "epoch: 12, running_loss: 5.1778321\n",
      "epoch: 13, running_loss: 5.2484322\n",
      "epoch: 14, running_loss: 5.1736584\n",
      "epoch: 15, running_loss: 3.4838572\n",
      "epoch: 16, running_loss: 3.4894445\n",
      "epoch: 17, running_loss: 4.2520990\n",
      "epoch: 18, running_loss: 3.2543511\n",
      "epoch: 19, running_loss: 3.5735407\n",
      "epoch: 20, running_loss: 4.3590875\n",
      "epoch: 21, running_loss: 2.7482116\n",
      "epoch: 22, running_loss: 3.2535014\n",
      "epoch: 23, running_loss: 2.8239551\n",
      "epoch: 24, running_loss: 3.0039120\n",
      "epoch: 25, running_loss: 3.2033491\n",
      "epoch: 26, running_loss: 3.4336164\n",
      "epoch: 27, running_loss: 2.4595416\n",
      "epoch: 28, running_loss: 3.2814422\n",
      "epoch: 29, running_loss: 3.0717723\n",
      "epoch: 30, running_loss: 2.8968637\n",
      "epoch: 31, running_loss: 2.5161242\n",
      "epoch: 32, running_loss: 1.9805100\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "running_loss =0\n",
    "# loop over epochs: one epoch = one pass through the whole training dataset\n",
    "for epoch in range(1, n_epochs+1):  \n",
    "#   loop over iterations: one iteration = 1 batch of examples\n",
    "    running_loss =0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # zero the gradient buffers\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() # Does the update\n",
    "    print ('epoch: %d, running_loss: %5.7f' % (epoch,running_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.9135 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %5.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
